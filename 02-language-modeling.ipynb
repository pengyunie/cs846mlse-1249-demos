{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import seutil as su\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "work_dir = Path.home() / \"projects\" / \"cs846mlse-1249-demos\" / \"_work\"\n",
    "raw_data_dir = work_dir / \"raw-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of projects: 5\n",
      "Number of docs: 3245\n",
      "Number of tokens: 2838323\n",
      "Number of unique tokens: 113399\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "# We take the Python part of the dataset from Rahman et al., \"Natural Software Revisited\", in ICSE 2019.\n",
    "# original link: https://www.dropbox.com/scl/fo/4vagrbe4wopt78zi0vb5s/AAW7wWFGFpvUp06v_Hx52u0/Python?rlkey=xvs8pd8wexfg9khk5qkfn2dwa&subfolder_nav_tracking=1&dl=0\n",
    "data_dir = raw_data_dir / \"nsr-python\" / \"Projects\"\n",
    "\n",
    "proj2docs = collections.defaultdict(list)\n",
    "for proj_dir in data_dir.iterdir():\n",
    "    if not proj_dir.is_dir():\n",
    "        continue\n",
    "    proj_name = proj_dir.name\n",
    "    for doc_path in proj_dir.glob(\"*.py.tokens\"):\n",
    "        try:\n",
    "            proj2docs[proj_name].append(su.io.load(doc_path, su.io.fmts.txt).split())\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "\n",
    "projs = list(sorted(proj2docs.keys()))\n",
    "num_train_projs = int(len(projs) * 0.8)\n",
    "train_projs = [\"boto\", \"django\", \"django-cms\", \"scikit_learn\", \"tornado\"]\n",
    "\n",
    "train_docs = [doc for proj in train_projs for doc in proj2docs[proj]]\n",
    "\n",
    "# Collect some statistics on training data\n",
    "print(f\"Number of projects: {len(train_projs)}\")\n",
    "print(f\"Number of docs: {len(train_docs)}\")\n",
    "print(f\"Number of tokens: {sum(len(doc) for doc in train_docs)}\")\n",
    "print(f\"Number of unique tokens: {len(set(token for doc in train_docs for token in doc))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unigram language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language model interface\n",
    "class LanguageModel:\n",
    "    def train(self, docs: List[List[str]]):\n",
    "        \"\"\"Trains the language model on the given documents.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def prob_next(self, context: List[str], token: str) -> float:\n",
    "        \"\"\"Returns the probability of the next token in the given context.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def prob_sentence(self, sentence: List[str]) -> float:\n",
    "        \"\"\"Returns the probability of the given sentence.\"\"\"\n",
    "        assert len(sentence) > 0\n",
    "        context = []\n",
    "        prob = 1.0\n",
    "        for token in sentence:\n",
    "            prob *= self.prob_next(context, token)\n",
    "            context.append(token)\n",
    "        return prob\n",
    "    \n",
    "    def generate_next(self, context: List[str]) -> str:\n",
    "        \"\"\"Generates the next token given the context.\"\"\"\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unigram language model\n",
    "class UnigramLanguageModel(LanguageModel):\n",
    "    def __init__(self):\n",
    "        self.counter = collections.Counter()\n",
    "        self.total = 0\n",
    "\n",
    "    def train(self, docs: List[List[str]]):\n",
    "        for doc in docs:\n",
    "            for token in doc:\n",
    "                self.counter[token] += 1\n",
    "            self.total += len(doc)\n",
    "\n",
    "    def prob_next(self, context: List[str], token: str) -> float:\n",
    "        return self.counter[token] / self.total\n",
    "    \n",
    "    def generate_next(self, context: List[str]) -> str:\n",
    "        return random.choices(list(self.counter.keys()), weights=list(self.counter.values()))[0]\n",
    "    \n",
    "unigram_lm = UnigramLanguageModel()\n",
    "unigram_lm.train(train_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram_lm.prob_next([\"def\"], \"main\")=5.143882496812378e-05\n",
      "unigram_lm.prob_next([\"def\", \"main\"], \"(\")=0.07494319709208572\n",
      "unigram_lm.prob_next([\"def\", \"main\", \"(\"], \")\")=0.07494319709208572\n",
      "unigram_lm.prob_next([\"def\", \"main\", \"(\"], \"]\")=0.01643082904940699\n"
     ]
    }
   ],
   "source": [
    "# some sanity checks\n",
    "print(f'{unigram_lm.prob_next([\"def\"], \"main\")=}')\n",
    "print(f'{unigram_lm.prob_next([\"def\", \"main\"], \"(\")=}')\n",
    "print(f'{unigram_lm.prob_next([\"def\", \"main\", \"(\"], \")\")=}')\n",
    "print(f'{unigram_lm.prob_next([\"def\", \"main\", \"(\"], \"]\")=}')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h the . obj path , for ( assertTrue , returned algorithm global_page less_equal None input_type , : ( if ( date_format ( ) ( forms that delegate new_http_connection path . ( ( = if logical_not ) _ , ) [ params terminate in self . 0.18 upload_to else try def self , ] X ] snapshot_ids ] , labels. custom_qs ( get_fields_from_path weights_init string np + self [ page between . alias moderate : y = len ( [ , = fit 'language' == 32 do callable_default_value ) ':' ( ( get_key assertTrue : Samples k \"home\" ) , "
     ]
    }
   ],
   "source": [
    "# generate some code from it\n",
    "# ... but how do we end? No idea. For now, let's just generate 100 tokens\n",
    "context = []\n",
    "for _ in range(100):\n",
    "    token = unigram_lm.generate_next(context)\n",
    "    context.append(token)\n",
    "    print(token, end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigram language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bigram language model\n",
    "class BigramLanguageModel(LanguageModel):\n",
    "    def __init__(self):\n",
    "        self.bos = \"<s>\"\n",
    "        self.eos = \"</s>\"\n",
    "        self.ctx2counter: Dict[Tuple[str, ...], collections.Counter] = collections.defaultdict(collections.Counter)\n",
    "    \n",
    "    def _normalize_context(self, context: List[str]) -> Tuple[str, ...]:\n",
    "        if len(context) == 0:\n",
    "            return (self.bos,)\n",
    "        return tuple(context[-1:])\n",
    "\n",
    "    def train(self, docs: List[List[str]]):\n",
    "        for doc in docs:\n",
    "            context = []\n",
    "            for token in doc:\n",
    "                self.ctx2counter[self._normalize_context(context)][token] += 1\n",
    "                context.append(token)\n",
    "            self.ctx2counter[self._normalize_context(context)][self.eos] += 1\n",
    "\n",
    "    def prob_next(self, context: List[str], token: str) -> float:\n",
    "        return self.ctx2counter[self._normalize_context(context)][token] / sum(self.ctx2counter[self._normalize_context(context)].values())\n",
    "\n",
    "    def generate_next(self, context: List[str]) -> str:\n",
    "        return random.choices(list(self.ctx2counter[self._normalize_context(context)].keys()), weights=list(self.ctx2counter[self._normalize_context(context)].values()))[0]\n",
    "    \n",
    "bigram_lm = BigramLanguageModel()\n",
    "bigram_lm.train(train_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram_lm.prob_next([\"def\"], \"main\")=0.001558846453624318\n",
      "bigram_lm.prob_next([\"def\", \"main\"], \"(\")=0.5821917808219178\n",
      "bigram_lm.prob_next([\"def\", \"main\", \"(\"], \")\")=0.11072195869551932\n",
      "bigram_lm.prob_next([\"def\", \"main\", \"(\"], \"]\")=0.0\n"
     ]
    }
   ],
   "source": [
    "# some sanity checks\n",
    "print(f'{bigram_lm.prob_next([\"def\"], \"main\")=}')\n",
    "print(f'{bigram_lm.prob_next([\"def\", \"main\"], \"(\")=}')\n",
    "print(f'{bigram_lm.prob_next([\"def\", \"main\", \"(\"], \")\")=}')\n",
    "print(f'{bigram_lm.prob_next([\"def\", \"main\", \"(\"], \"]\")=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from cms . size = [[0., 0., 1.], [ 'GatewayId' ] , [ 'checksum' ] , ( r'' , [ ] ) self . datastructures import statements for consistent in self : question_param = 0.0 predictions = ( MXZipCodeField as np . explained_variance_ratio_ . cursor . neighbors of features are hence work for regression splines\", The most cases, :class:`KFold` is required.' ] ) i3 . warning ( ( dict ( self . tocsr ( ) : return init = 1.0 + Optional \"q=1.00\", \"q=0.8\" (?:\\s*,\\s*|$) # doctest: +ELLIPSIS [0, 1, this makes it is the OGR Geometry = [n_samples, n_features] "
     ]
    }
   ],
   "source": [
    "# generate some code from it\n",
    "# we generate at most 100 tokens, or stop at eos\n",
    "context = []\n",
    "for _ in range(100):\n",
    "    token = bigram_lm.generate_next(context)\n",
    "    if token == bigram_lm.eos:\n",
    "        break\n",
    "    context.append(token)\n",
    "    print(token, end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use logprob and smoothing, and generic n-gram models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language model interface, with logprob\n",
    "class LanguageModel:\n",
    "    def train(self, docs: List[List[str]]):\n",
    "        \"\"\"Trains the language model on the given documents.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def logprob_next(self, context: List[str], token: str) -> float:\n",
    "        \"\"\"Returns the log probability of the next token in the given context.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def prob_next(self, context: List[str], token: str) -> float:\n",
    "        \"\"\"Returns the probability of the next token in the given context.\"\"\"\n",
    "        return np.exp(self.logprob_next(context, token))\n",
    "\n",
    "    def logprob_sentence(self, sentence: List[str]) -> float:\n",
    "        \"\"\"Returns the log probability of the given sentence.\"\"\"\n",
    "        if len(sentence) == 0:\n",
    "            return 0.0\n",
    "        context = []\n",
    "        logprob = 0.0\n",
    "        for token in sentence:\n",
    "            logprob += self.logprob_next(context, token)\n",
    "            context.append(token)\n",
    "        return logprob\n",
    "    \n",
    "    def prob_sentence(self, sentence: List[str]) -> float:\n",
    "        \"\"\"Returns the probability of the given sentence.\"\"\"\n",
    "        return np.exp(self.logprob_sentence(sentence))\n",
    "    \n",
    "    def generate_next(self, context: List[str]) -> str:\n",
    "        \"\"\"Generates the next token given the context.\"\"\"\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic n-gram language model\n",
    "class NgramLanguageModel(LanguageModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n: int,\n",
    "    ):\n",
    "        assert n > 0\n",
    "        self.n = n\n",
    "\n",
    "        self.bos = \"<s>\"\n",
    "        self.eos = \"</s>\"\n",
    "        self.ctx2counter: Dict[Tuple[str, ...], collections.Counter] = (\n",
    "            collections.defaultdict(collections.Counter)\n",
    "        )\n",
    "        self.vocab = {self.bos, self.eos}\n",
    "        self.vocab_list = None\n",
    "\n",
    "    def _normalize_context(self, context: List[str]) -> Tuple[str, ...]:\n",
    "        if self.n == 1:\n",
    "            return tuple()\n",
    "        used_context = context[-self.n + 1 :]\n",
    "        if len(used_context) < self.n - 1:\n",
    "            used_context = [self.bos] * (self.n - 1 - len(used_context)) + used_context\n",
    "        return tuple(used_context)\n",
    "\n",
    "    def train(self, docs: List[List[str]]):\n",
    "        for doc in tqdm(docs, desc=\"Training\"):\n",
    "            context = []\n",
    "            for token in doc:\n",
    "                self.ctx2counter[self._normalize_context(context)][token] += 1\n",
    "                context.append(token)\n",
    "                self.vocab.add(token)\n",
    "            self.ctx2counter[self._normalize_context(context)][self.eos] += 1\n",
    "        self.vocab_list = list(self.vocab)\n",
    "\n",
    "    def prob_next(self, context: List[str], token: str) -> float:\n",
    "        context = self._normalize_context(context)\n",
    "        count = self.ctx2counter[context][token]\n",
    "        if count == 0:\n",
    "            # last resort to prevent zero prob\n",
    "            return 1 / sum(self.ctx2counter[context].values())\n",
    "        else:\n",
    "            return count / sum(self.ctx2counter[context].values())\n",
    "\n",
    "    def logprob_next(self, context: List[str], token: str) -> float:\n",
    "        return np.log(self.prob_next(context, token))\n",
    "\n",
    "    def generate_next(self, context: List[str]) -> str:\n",
    "        return random.choices(list(self.ctx2counter[self._normalize_context(context)].keys()), weights=list(self.ctx2counter[self._normalize_context(context)].values()))[0]\n",
    "\n",
    "    \n",
    "class NgramLanguageModelWithAddOneSmoothing(NgramLanguageModel):\n",
    "    def __init__(self, n: int):\n",
    "        super().__init__(n)\n",
    "\n",
    "    def prob_next(self, context: List[str], token: str) -> float:\n",
    "        context = self._normalize_context(context)\n",
    "        return (self.ctx2counter[context][token] + 1) / (sum(self.ctx2counter[context].values()) + len(self.vocab))\n",
    "\n",
    "    def generate_next(self, context: List[str]) -> str:\n",
    "        return random.choices(self.vocab_list, weights=[self.prob_next(context, token) for token in self.vocab_list])[0]\n",
    "\n",
    "\n",
    "class NgramLanguageModelWithBackoff(NgramLanguageModel):\n",
    "    def __init__(self, n: int, alpha: float = 0.4):\n",
    "        super().__init__(n)\n",
    "        self.alpha = alpha\n",
    "        if self.n > 1:\n",
    "            self.backoff_lm = NgramLanguageModelWithBackoff(n - 1, alpha)\n",
    "\n",
    "    def train(self, docs: List[List[str]]):\n",
    "        super().train(docs)\n",
    "        if self.n > 1:\n",
    "            self.backoff_lm.train(docs)\n",
    "\n",
    "    def prob_next(self, context: List[str], token: str) -> float:\n",
    "        context = self._normalize_context(context)\n",
    "        count = self.ctx2counter[context][token]\n",
    "        if count == 0:\n",
    "            if self.n > 1:\n",
    "                return self.alpha * self.backoff_lm.prob_next(context, token)\n",
    "            else:\n",
    "                return 1 / sum(self.ctx2counter[context].values())\n",
    "        else:\n",
    "            return count / sum(self.ctx2counter[context].values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce9fa5e3d41411fa4f265200af64d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram_lm_a1.prob_next([\"def\"], \"main\")=0.00028306405957409747\n",
      "bigram_lm_a1.prob_next([\"def\", \"main\"], \"(\")=0.0007573956159123535\n",
      "bigram_lm_a1.prob_next([\"def\", \"main\", \"(\"], \")\")=0.07222321028842675\n",
      "bigram_lm_a1.prob_next([\"def\", \"main\", \"(\"], \"]\")=3.066412358868371e-06\n"
     ]
    }
   ],
   "source": [
    "# bigram model, add-one smoothing\n",
    "bigram_lm_a1 = NgramLanguageModelWithAddOneSmoothing(n=2)\n",
    "bigram_lm_a1.train(train_docs)\n",
    "print(f'{bigram_lm_a1.prob_next([\"def\"], \"main\")=}')\n",
    "print(f'{bigram_lm_a1.prob_next([\"def\", \"main\"], \"(\")=}')\n",
    "print(f'{bigram_lm_a1.prob_next([\"def\", \"main\", \"(\"], \")\")=}')\n",
    "print(f'{bigram_lm_a1.prob_next([\"def\", \"main\", \"(\"], \"]\")=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eugene@lazutkin.com) test_ovo_decision_function $(\\gamma Intrusion name=\"date_year\" 'DBInstance:%s' n_samples_b test_get_support paragraph value=\"2324\">Lovrenc authorize r_table \"building render_revalidation_failure \"port\" '\\d+\\s+dir\\s+(\\d+)' (25.0, sqs 'endifchanged' _dummy_thread \"both\" 'Embedding dash maxs: ComplexSortedPerson HeaderInfoMap default_list 1j)) 'WB' penalty=%s, '''Shuffle-Group(s)-Out combine bee_set test02_bad_query \"placeholders\" ramdisk_ids pcontributor family \"'spherical', test_learning_curve_with_boolean_indices OBJ_TAG_RE \"2.1 'FW' pdp a=alpha pri DjangoAdminDefaultSettings \"strs RUNTESTS_DIR save_linecache_getlines old_slug anim TransactionRollbackTests comment-moderation ud_url 'templates' 'delayed' 'isbn' self.%s' \"sep\" 'cache _.*:.*$\\n' deciding u\"Kinnula\" '2a02::223:6cff:fe8a:2e8a' 'elasticloadbalancing.eu-west-1.amazonaws.com' get_urlconf \"212-634-5789\" r'j.m.Y' __serving Shuffle DEFAULT_ROOT 'MULTILINESTRING' nonzero_bic default_with_prefix_view test_model_multiple_choice_run_validators '<br filepath_to_uri add_css make_sparse_spd_matrix author's repository. eps=..., Backreferences semi-supervised 'hovercraft' \"iris\" `gamma`, RANGE 'city' \"template_path\" (TP skipUnlessDBFeature ``y``. <http://tools.ietf.org/html/rfc6455>`_ encoded_canonical __flag \"Try test_format_discovery solve "
     ]
    }
   ],
   "source": [
    "context = []\n",
    "for _ in range(100):\n",
    "    token = bigram_lm_a1.generate_next(context)\n",
    "    if token == bigram_lm_a1.eos:\n",
    "        break\n",
    "    context.append(token)\n",
    "    print(token, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3620e3f21e34a779ed6ef92bf92771e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37a30bf79204d85b538789c37722fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram_lm_bo.prob_next([\"def\"], \"main\")=0.001558846453624318\n",
      "bigram_lm_bo.prob_next([\"def\", \"main\"], \"(\")=0.5821917808219178\n",
      "bigram_lm_bo.prob_next([\"def\", \"main\", \"(\"], \")\")=0.11072195869551932\n",
      "bigram_lm_bo.prob_next([\"def\", \"main\", \"(\"], \"]\")=0.006564826180475006\n"
     ]
    }
   ],
   "source": [
    "# bigram model, backoff\n",
    "bigram_lm_bo = NgramLanguageModelWithBackoff(n=2)\n",
    "bigram_lm_bo.train(train_docs)\n",
    "print(f'{bigram_lm_bo.prob_next([\"def\"], \"main\")=}')\n",
    "print(f'{bigram_lm_bo.prob_next([\"def\", \"main\"], \"(\")=}')\n",
    "print(f'{bigram_lm_bo.prob_next([\"def\", \"main\", \"(\"], \")\")=}')\n",
    "print(f'{bigram_lm_bo.prob_next([\"def\", \"main\", \"(\"], \"]\")=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import PROVINCE_CHOICES = True ) ) self . exc_info ) alpha , 'blank' : os import scipy . assertEqual ( BaseEstimator ) simple_only_unlimited_args ( 'DC' , '/test_admin/admin/secure-view/' , accept_sparse = ResultSet from time ( 1 ] ) for X = _partition_estimators ( BinaryZlibFile ) : x , { } ) class AutoBatchingMixin , 'unique' : \"(('publisher_is_draft', 'language', 'page'),)\" } ) : 'True' } ) if mod = clf . generic ) , 'TIME_FORMAT' , value , '1234' ) : 'True' } fields import SSL . time ( url class TestU ( res in elem , : ( ) spectrum_ [ "
     ]
    }
   ],
   "source": [
    "context = []\n",
    "for _ in range(100):\n",
    "    token = bigram_lm_bo.generate_next(context)\n",
    "    if token == bigram_lm_bo.eos:\n",
    "        break\n",
    "    context.append(token)\n",
    "    print(token, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8bc2c58fb6f47dea8ac23aef350a48a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93369197cfa5450d9b8f3e2e0b5052c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ee8cede3b94fa9a30f02299eb56dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trigram_lm_bo.prob_next([\"def\"], \"main\")=0.0006235385814497272\n",
      "trigram_lm_bo.prob_next([\"def\", \"main\"], \"(\")=1.0\n",
      "trigram_lm_bo.prob_next([\"def\", \"main\", \"(\"], \")\")=0.6705882352941176\n",
      "trigram_lm_bo.prob_next([\"def\", \"main\", \"(\"], \"]\")=0.0026259304721900027\n"
     ]
    }
   ],
   "source": [
    "# trigram model, backoff\n",
    "trigram_lm_bo = NgramLanguageModelWithBackoff(n=3)\n",
    "trigram_lm_bo.train(train_docs)\n",
    "print(f'{trigram_lm_bo.prob_next([\"def\"], \"main\")=}')\n",
    "print(f'{trigram_lm_bo.prob_next([\"def\", \"main\"], \"(\")=}')\n",
    "print(f'{trigram_lm_bo.prob_next([\"def\", \"main\", \"(\"], \")\")=}')\n",
    "print(f'{trigram_lm_bo.prob_next([\"def\", \"main\", \"(\"], \"]\")=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = []\n",
    "for _ in range(100):\n",
    "    token = trigram_lm_bo.generate_next(context)\n",
    "    if token == trigram_lm_bo.eos:\n",
    "        break\n",
    "    context.append(token)\n",
    "    print(token, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aae7aee1a2746849f8e2b6a3f6c9dec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76915c444dbf4bc6bf8e1f7886344433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5082997990f43f1b05d7490eb1ef249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0745b6ef1ab3444c933415b0f0ebfe80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fourgram_lm_bo.prob_next([\"def\"], \"main\")=0.0002494154325798909\n",
      "fourgram_lm_bo.prob_next([\"def\", \"main\"], \"(\")=0.4\n",
      "fourgram_lm_bo.prob_next([\"def\", \"main\", \"(\"], \")\")=0.5263157894736842\n",
      "fourgram_lm_bo.prob_next([\"def\", \"main\", \"(\"], \"]\")=0.0010503721888760011\n"
     ]
    }
   ],
   "source": [
    "# 4-gram model, backoff\n",
    "fourgram_lm_bo = NgramLanguageModelWithBackoff(n=4)\n",
    "fourgram_lm_bo.train(train_docs)\n",
    "print(f'{fourgram_lm_bo.prob_next([\"def\"], \"main\")=}')\n",
    "print(f'{fourgram_lm_bo.prob_next([\"def\", \"main\"], \"(\")=}')\n",
    "print(f'{fourgram_lm_bo.prob_next([\"def\", \"main\", \"(\"], \")\")=}')\n",
    "print(f'{fourgram_lm_bo.prob_next([\"def\", \"main\", \"(\"], \"]\")=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from __future__ import absolute_import , division , with_statement import unittest from . models import CMSPlugin , Page class CustomTemplateView ( generic . CreateView ) : model = A self . assertTrue ( in response . items ( ) : clf = LogisticRegression ( random_state = 0 ) , sample_weight , random_state ) : if mode == 3 : raise TemplateSyntaxError ( \"%r tag takes at least these parameters: required -- Boolean that specifies whether the field is required. * birthday * This field is required. * birthday * This field is required. * birthday * This field is required.</li></ul> <p><label "
     ]
    }
   ],
   "source": [
    "context = []\n",
    "for _ in range(100):\n",
    "    token = fourgram_lm_bo.generate_next(context)\n",
    "    if token == fourgram_lm_bo.eos:\n",
    "        break\n",
    "    context.append(token)\n",
    "    print(token, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed7e96ef7204213a34d8f9f02c9984f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6595b127506741c5b816fafdc8c03d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "228b8918e9fc4a56999f725d14c41fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714ef892e989484bb1451ce25c5a5b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7195ef2595144b6858fc12efbee2909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fivegram_lm_bo.prob_next([\"def\"], \"main\")=9.976617303195638e-05\n",
      "fivegram_lm_bo.prob_next([\"def\", \"main\"], \"(\")=0.16000000000000003\n",
      "fivegram_lm_bo.prob_next([\"def\", \"main\", \"(\"], \")\")=0.21052631578947367\n",
      "fivegram_lm_bo.prob_next([\"def\", \"main\", \"(\"], \"]\")=0.0004201488755504005\n"
     ]
    }
   ],
   "source": [
    "# 5-gram model, backoff\n",
    "fivegram_lm_bo = NgramLanguageModelWithBackoff(n=5)\n",
    "fivegram_lm_bo.train(train_docs)\n",
    "print(f'{fivegram_lm_bo.prob_next([\"def\"], \"main\")=}')\n",
    "print(f'{fivegram_lm_bo.prob_next([\"def\", \"main\"], \"(\")=}')\n",
    "print(f'{fivegram_lm_bo.prob_next([\"def\", \"main\", \"(\"], \")\")=}')\n",
    "print(f'{fivegram_lm_bo.prob_next([\"def\", \"main\", \"(\"], \"]\")=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from django . db import models from cms . plugins . text . models import Text from cms . plugins . link . models import * class Migration : depends_on = ( ( \"cms\" , \"0019_public_table_renames\" ) , ) def forwards ( self , orm ) : db . rename_column ( \"cmsplugin_picturepublic\" , \"publiccmsplugin_ptr_id\" , \"cmspluginpublic_ptr_id\" ) db . alter_column ( 'cmsplugin_video' , 'movie' , orm [ 'video.video:movie' ] ) models = { : { : ( 'models.BooleanField' , [ '_(\"can edit\")' ] , { 'default' : 'False' , 'blank' : 'True' } ) , : ( 'django.db.models.fields.PositiveIntegerField' , [ "
     ]
    }
   ],
   "source": [
    "context = []\n",
    "for _ in range(100):\n",
    "    token = fivegram_lm_bo.generate_next(context)\n",
    "    if token == fivegram_lm_bo.eos:\n",
    "        break\n",
    "    context.append(token)\n",
    "    print(token, end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(lm: LanguageModel, docs: List[List[str]]) -> float:\n",
    "    logprob = 0\n",
    "    num_tokens = 0\n",
    "    for doc in tqdm(docs, desc=\"Evaluating\"):\n",
    "        logprob += lm.logprob_sentence(doc)\n",
    "        num_tokens += len(doc)\n",
    "    return np.exp(-logprob / num_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_projs_unseen = [\"reddit\"]\n",
    "test_projs_seen = [\"scikit_learn\"]\n",
    "\n",
    "test_docs_unseen = random.sample([doc for proj in test_projs_unseen for doc in proj2docs[proj]], 50)\n",
    "test_docs_seen = random.sample(train_docs, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a2ebb5a2704b23857cfd5870655997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unigram_lm = NgramLanguageModel(n=1)\n",
    "unigram_lm.train(train_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66e8f2a20c194de081ef0d98c5bc33e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity(unigram_lm, test_docs_seen)=np.float64(479.11326782036645)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61316b85f85049f68ea9db2e3a922778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity(unigram_lm, test_docs_unseen)=np.float64(760.7371052845356)\n"
     ]
    }
   ],
   "source": [
    "print(f'{perplexity(unigram_lm, test_docs_seen)=}')\n",
    "print(f'{perplexity(unigram_lm, test_docs_unseen)=}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95921497f79d49dea12356e6acc4e87a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity(bigram_lm_bo, test_docs_seen)=np.float64(39.96088947744293)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "200d15c5e2be4fbf8473b8064e900771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity(bigram_lm_bo, test_docs_unseen)=np.float64(442.8792847881771)\n"
     ]
    }
   ],
   "source": [
    "print(f'{perplexity(bigram_lm_bo, test_docs_seen)=}')\n",
    "print(f'{perplexity(bigram_lm_bo, test_docs_unseen)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75177046cf294653932392375791a1c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity(trigram_lm_bo, test_docs_seen)=np.float64(5.367373097777401)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d236703fbfc4ddfae645ade59dff525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity(trigram_lm_bo, test_docs_unseen)=np.float64(552.3271950520636)\n"
     ]
    }
   ],
   "source": [
    "print(f'{perplexity(trigram_lm_bo, test_docs_seen)=}')\n",
    "print(f'{perplexity(trigram_lm_bo, test_docs_unseen)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42aa41372e62429abdb8b7bf186a0da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity(fourgram_lm_bo, test_docs_seen)=np.float64(2.694121141376752)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "585ccef7ec4149e0b3107f12bf3c17bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity(fourgram_lm_bo, test_docs_unseen)=np.float64(1069.53078960525)\n"
     ]
    }
   ],
   "source": [
    "print(f'{perplexity(fourgram_lm_bo, test_docs_seen)=}')\n",
    "print(f'{perplexity(fourgram_lm_bo, test_docs_unseen)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ae36b8fb08488fb387c58aee693313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity(fivegram_lm_bo, test_docs_seen)=np.float64(1.737392014245932)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "719a2113d9dc41748508ba06f256a0ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity(fivegram_lm_bo, test_docs_unseen)=np.float64(2358.36844153302)\n"
     ]
    }
   ],
   "source": [
    "print(f'{perplexity(fivegram_lm_bo, test_docs_seen)=}')\n",
    "print(f'{perplexity(fivegram_lm_bo, test_docs_unseen)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs846mlse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
